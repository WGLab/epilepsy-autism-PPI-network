{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables to be updated/configured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WES = False # False if running for the larger epilepsy-autism multiplex network, True if running for the WES multiplex network\n",
    "if WES:\n",
    "    FIGURES_DIR = \"figures_wes\" # path to directory where figures will the saved (creates the directory if it doesn't exist)\n",
    "else:\n",
    "    FIGURES_DIR = \"figures\" # path to directory where figures will the saved (creates the directory if it doesn't exist)\n",
    "GRAPH_DIR = \"gexf_files\" # path to directory where the .gexf files are located\n",
    "INFO_DIR = \"network_info\" # path to directory with information on each gene/node in the multiplex network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# network packages\n",
    "import networkx as nx\n",
    "from networkx.algorithms.operators.binary import intersection\n",
    "from networkx.generators.degree_seq import expected_degree_graph\n",
    "from networkx.readwrite.gexf import read_gexf\n",
    "from cdlib import evaluation\n",
    "import igraph as ig\n",
    "import louvain\n",
    "\n",
    "# visualization packages\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# other packages\n",
    "from math import log10, floor\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# stats packages    \n",
    "import scikit_posthocs as sp\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import stats\n",
    "\n",
    "import uncertainties.unumpy as unp\n",
    "import uncertainties as unc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(FIGURES_DIR):\n",
    "    os.makedirs(FIGURES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting settings\n",
    "font = {'size': 14}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data and get statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WES:\n",
    "    gene_phenotype_filename = 'gene-phenotype-wes-1-500-update.gexf'\n",
    "    gene_ppi_filename = \"gene-ppi-wes-700-update.gexf\"\n",
    "    gene_union_filename = 'gene-union-wes.gexf'\n",
    "    info_filename = 'info_wes_df.csv'\n",
    "else:\n",
    "    gene_phenotype_filename = 'gene-phenotype-1-1000-update.gexf'\n",
    "    gene_ppi_filename = 'gene-ppi-700-update.gexf'\n",
    "    gene_union_filename = 'gene-union.gexf'\n",
    "    info_filename = 'info_df.csv'\n",
    "    \n",
    "info_df = pd.read_csv(os.path.join(INFO_DIR, info_filename))\n",
    "gene_phenotype = read_gexf(os.path.join(GRAPH_DIR, gene_phenotype_filename))\n",
    "gene_ppi = read_gexf(os.path.join(GRAPH_DIR, gene_ppi_filename))\n",
    "gene_union = read_gexf(os.path.join(GRAPH_DIR, gene_union_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gene PPI layer')\n",
    "print(nx.info(gene_ppi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Gene Phenotype layer')\n",
    "print(nx.info(gene_phenotype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degree distribution of PPI and phenotype layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ppi_degree = info_df['ppi_degree']\n",
    "gene_phenotype_degree = info_df['phenotype_degree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WES:\n",
    "    bins = 15\n",
    "else:\n",
    "    bins = 30\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(gene_ppi_degree, bins=bins, density=True, label='PPI', alpha=0.5)\n",
    "plt.hist(gene_phenotype_degree, bins=bins, density=True, label='Phenotype', alpha=0.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.savefig(os.path.join(FIGURES_DIR, \"degree_distribution_ppi_and_phenotype.eps\"), dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significance of overlapping edges between PPI and phenotype layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = intersection(gene_phenotype, gene_ppi)\n",
    "overlapping_edges = len(I.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 10000\n",
    "edge_overlap = []\n",
    "for i in range(0, num_trials):\n",
    "    if i % 100 == 0:\n",
    "        print(\"Trial:\", i)\n",
    "    gene_phenotype_random = expected_degree_graph(gene_phenotype_degree, seed=None, selfloops=False)\n",
    "    gene_ppi_random = expected_degree_graph(gene_ppi_degree, seed=None, selfloops=False) \n",
    "    I_random = intersection(gene_phenotype_random, gene_ppi_random)\n",
    "    edge_overlap.append(len(I_random.edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# significant number of overlapping edges\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(edge_overlap, bins=15, density=True, label='edge_overlap')\n",
    "plt.axvline(overlapping_edges, color='red')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Number of overlapping edges')\n",
    "plt.savefig(os.path.join(FIGURES_DIR, \"overlapping_edges.eps\"), dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype and PPI degree correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code copied from https://apmonitor.com/che263/index.php/Main/PythonRegressionStatistics\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "x = info_df['phenotype_degree']\n",
    "y = info_df['ppi_degree']\n",
    "n = len(y)\n",
    "\n",
    "def f(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "popt, pcov = curve_fit(f, x, y)\n",
    "\n",
    "# retrieve parameter values\n",
    "a = popt[0]\n",
    "b = popt[1]\n",
    "print('Optimal Values')\n",
    "print('a: ' + str(a))\n",
    "print('b: ' + str(b))\n",
    "\n",
    "# compute r^2\n",
    "r2 = 1.0-(sum((y-f(x,a,b))**2)/((n-1.0)*np.var(y,ddof=1)))\n",
    "print('R^2: ' + str(r2))\n",
    "\n",
    "# calculate parameter confidence interval\n",
    "a,b = unc.correlated_values(popt, pcov)\n",
    "print('Uncertainty')\n",
    "print('a: ' + str(a))\n",
    "print('b: ' + str(b))\n",
    "\n",
    "# plot data\n",
    "plt.scatter(x, y, s=3, alpha=0.5)\n",
    "\n",
    "# calculate regression confidence interval\n",
    "if WES:\n",
    "    px = np.linspace(0, 20, 100)\n",
    "else:\n",
    "    px = np.linspace(0, 150, 100)\n",
    "    \n",
    "py = a*px+b\n",
    "nom = unp.nominal_values(py)\n",
    "std = unp.std_devs(py)\n",
    "\n",
    "def predband(x, xd, yd, p, func, conf=0.95):\n",
    "    # x = requested points\n",
    "    # xd = x data\n",
    "    # yd = y data\n",
    "    # p = parameters\n",
    "    # func = function name\n",
    "    alpha = 1.0 - conf    # significance\n",
    "    N = xd.size          # data sample size\n",
    "    var_n = len(p)  # number of parameters\n",
    "    # Quantile of Student's t distribution for p=(1-alpha/2)\n",
    "    q = stats.t.ppf(1.0 - alpha / 2.0, N - var_n)\n",
    "    # Stdev of an individual measurement\n",
    "    se = np.sqrt(1. / (N - var_n) * \\\n",
    "                 np.sum((yd - func(xd, *p)) ** 2))\n",
    "    # Auxiliary definitions\n",
    "    sx = (x - xd.mean()) ** 2\n",
    "    sxd = np.sum((xd - xd.mean()) ** 2)\n",
    "    # Predicted values (best-fit model)\n",
    "    yp = func(x, *p)\n",
    "    # Prediction band\n",
    "    dy = q * se * np.sqrt(1.0+ (1.0/N) + (sx/sxd))\n",
    "    # Upper & lower prediction bands.\n",
    "    lpb, upb = yp - dy, yp + dy\n",
    "    return lpb, upb\n",
    "\n",
    "lpb, upb = predband(px, x, y, popt, f, conf=0.95)\n",
    "\n",
    "# plot the regression\n",
    "plt.plot(px, nom, c='black', label='fit')\n",
    "\n",
    "# uncertainty lines (95% confidence)\n",
    "plt.plot(px, nom - 1.96 * std, c='red',\\\n",
    "         label='95% confidence region')\n",
    "plt.plot(px, nom + 1.96 * std, c='red')\n",
    "# prediction band (95% confidence)\n",
    "plt.plot(px, lpb, 'k--',label='95% prediction band')\n",
    "plt.plot(px, upb, 'k--')\n",
    "plt.ylabel('PPI degree')\n",
    "plt.xlabel('Phenotype degree')\n",
    "plt.legend(loc='best', fontsize=12)\n",
    "plt.savefig(os.path.join(FIGURES_DIR, \"degree_correlation.eps\"), dpi=600)\n",
    "\n",
    "# save and show figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity of modules between PPI and phenotype layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper for communities\n",
    "class Coms:\n",
    "    def __init__(self, communities):\n",
    "        self.communities = communities\n",
    "        self.overlap = None\n",
    "        \n",
    "# get Coms class with genes from annotated networkx graph\n",
    "def get_coms_from_graph(G):    \n",
    "    max_module = max([G.nodes[node]['module'] for node in G.nodes])\n",
    "    partition = []\n",
    "    for i in range(max_module):\n",
    "        partition.append([])\n",
    "    for node in G.nodes:\n",
    "        mod = G.nodes[node]['module']\n",
    "        partition[mod-1] = partition[mod-1] + [node]\n",
    "    coms = Coms(partition)\n",
    "    return coms\n",
    "\n",
    "# takes partition with IDs and converts to Coms class with genes\n",
    "def partition_to_genes(partition):\n",
    "    partition_genes = []\n",
    "    for com in partition:\n",
    "        com_genes = []\n",
    "        for g in com:\n",
    "            com_genes.append(id_to_gene[g])\n",
    "        partition_genes.append(com_genes) \n",
    "    coms = Coms(list(partition_genes))\n",
    "    return coms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def networkx_to_igraph(G, d):\n",
    "    g = ig.Graph()\n",
    "    g.add_vertices([d[g] for g in set(G.nodes)])\n",
    "    g.add_edges([(d[e[0]], d[e[1]]) for e in set(G.edges)])    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_to_id = pd.Series(info_df.index.values,index=info_df['gene']).to_dict()\n",
    "id_to_gene = pd.Series(info_df['gene'].values).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coms_phenotype = get_coms_from_graph(gene_phenotype)\n",
    "coms_ppi = get_coms_from_graph(gene_ppi)\n",
    "coms_multiplex = get_coms_from_graph(gene_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_phenotype = evaluation.newman_girvan_modularity(gene_phenotype, coms_phenotype)\n",
    "print(\"Phenotype layer modularity:\", round(mod_phenotype.score, 3))\n",
    "print(\"Total number of phenotype modules:\", len(coms_phenotype.communities))\n",
    "print(\"Total number of phenotype modules with at least 20 genes:\", len([com for com in coms_phenotype.communities if len(com)>=20]))\n",
    "print(\"Total number of phenotype modules with at least 5 genes:\", len([com for com in coms_phenotype.communities if len(com)>=5]))\n",
    "print()\n",
    "mod_ppi = evaluation.newman_girvan_modularity(gene_ppi, coms_ppi)\n",
    "print(\"PPI layer modularity:\", round(mod_ppi.score, 3))\n",
    "print(\"Total number of PPI modules:\", len(coms_ppi.communities))\n",
    "print(\"Total number of PPI modules with at least 20 genes:\", len([com for com in coms_ppi.communities if len(com)>=20]))\n",
    "print(\"Total number of PPI modules with at least 5 genes:\", len([com for com in coms_ppi.communities if len(com)>=5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_calc = evaluation.normalized_mutual_information(coms_phenotype, coms_ppi).score\n",
    "print('Normalized mutual information of PPI and phenotype layer =', similarity_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = []\n",
    "num_trials = 1000\n",
    "for i in range(0, num_trials):\n",
    "    if i % 50 == 0:\n",
    "        print(\"Trial =\", i)\n",
    "    gene_phenotype_random = expected_degree_graph(gene_phenotype_degree, seed=None, selfloops=False)\n",
    "    gene_ppi_random = expected_degree_graph(gene_ppi_degree, seed=None, selfloops=False)\n",
    "    \n",
    "    # networkx to igraph\n",
    "    gene_phenotype_random = networkx_to_igraph(gene_phenotype_random, {k:k for k in gene_to_id.values()})\n",
    "    gene_ppi_random = networkx_to_igraph(gene_ppi_random, {k:k for k in gene_to_id.values()})\n",
    "    \n",
    "    partition_phenotype_random = louvain.find_partition(gene_phenotype_random, louvain.ModularityVertexPartition)\n",
    "    partition_ppi_random = louvain.find_partition(gene_ppi_random, louvain.ModularityVertexPartition)\n",
    "    \n",
    "    coms_phenotype_random = partition_to_genes(partition_phenotype_random)\n",
    "    coms_ppi_random = partition_to_genes(partition_ppi_random)\n",
    "\n",
    "    #jaccard.append(calculate_jaccard_index_modules(coms_phenotype_random, coms_ppi_random))\n",
    "    similarity.append(evaluation.normalized_mutual_information(coms_phenotype_random, coms_ppi_random).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# significant number of overlapping modules\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(similarity, bins=20, density=True, label='normalized mutual information')\n",
    "plt.axvline(similarity_calc, color='red')\n",
    "\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Normalized mutual information')\n",
    "plt.savefig(os.path.join(FIGURES_DIR, \"NMI.eps\"), dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centrality and of epilepsy- and autism-specific genes and common genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_sig(x, sig=3):\n",
    "    return round(x, sig-int(floor(log10(abs(x))))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i, row in info_df.iterrows():        \n",
    "    if row['common_all'] == 1:\n",
    "        temp.append(list(row.values) + ['common_all'])\n",
    "    if row['a_specific'] == 1:\n",
    "        temp.append(list(row.values) + ['autism_specific'])\n",
    "    if row['e_specific'] == 1:\n",
    "        temp.append(list(row.values) + ['epilepsy_specific'])\n",
    "df = pd.DataFrame(temp)\n",
    "df.columns = list(info_df.columns) + ['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_info = df.melt(id_vars=['gene', 'type'], value_vars=['ppi_degree', 'phenotype_degree'], var_name=\"graph\", value_name=\"degree\")\n",
    "degree_info = degree_info.replace({'graph': {'ppi_degree': 'PPI', 'phenotype_degree': 'Phenotype'}})\n",
    "bc_info = df.melt(id_vars=['gene', 'type'], value_vars=['ppi_betweenness', 'phenotype_betweenness'], var_name=\"graph\", value_name=\"betweenness\")\n",
    "bc_info = bc_info.replace({'graph': {'ppi_betweenness': 'PPI', 'phenotype_betweenness': 'Phenotype'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPI degree Kruskal–Wallis H test\n",
    "var = 'ppi_degree'\n",
    "x = list(df[df['type']=='epilepsy_specific'][var])\n",
    "y = list(df[df['type']=='autism_specific'][var])\n",
    "z = list(df[df['type']=='common_all'][var])\n",
    "\n",
    "stat, pval = stats.kruskal(x, y, z)\n",
    "print(f\"Statistic = {round_sig(stat)}, p-value = {round_sig(pval)}\")\n",
    "ppi_degree = sp.posthoc_mannwhitney([x, y, z], p_adjust='bonferroni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phenotype degree Kruskal–Wallis H test\n",
    "var = 'phenotype_degree'\n",
    "x = list(df[df['type']=='epilepsy_specific'][var])\n",
    "y = list(df[df['type']=='autism_specific'][var])\n",
    "z = list(df[df['type']=='common_all'][var])\n",
    "\n",
    "stat, pval = stats.kruskal(x, y, z)\n",
    "print(f\"Statistic = {round_sig(stat)}, p-value = {round_sig(pval)}\")\n",
    "phenotype_degree = sp.posthoc_mannwhitney([x, y, z], p_adjust='bonferroni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPI betweenness centrality (BC) Kruskal–Wallis H test\n",
    "var = 'ppi_betweenness'\n",
    "x = list(df[df['type']=='epilepsy_specific'][var])\n",
    "y = list(df[df['type']=='autism_specific'][var])\n",
    "z = list(df[df['type']=='common_all'][var])\n",
    "\n",
    "stat, pval = stats.kruskal(x, y, z)\n",
    "print(f\"Statistic = {round_sig(stat)}, p-value = {round_sig(pval)}\")\n",
    "ppi_bc = sp.posthoc_mannwhitney([x, y, z], p_adjust='bonferroni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phenotype betweenness centrality (BC) Kruskal–Wallis H test\n",
    "var = 'phenotype_betweenness'\n",
    "x = list(df[df['type']=='epilepsy_specific'][var])\n",
    "y = list(df[df['type']=='autism_specific'][var])\n",
    "z = list(df[df['type']=='common_all'][var])\n",
    "\n",
    "stat, pval = stats.kruskal(x, y, z)\n",
    "print(f\"Statistic = {round_sig(stat)}, p-value = {round_sig(pval)}\")\n",
    "phenotype_bc = sp.posthoc_mannwhitney([x, y, z], p_adjust='bonferroni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_info_ppi = degree_info[degree_info['graph']=='PPI'].groupby(['type'])['degree'].agg(['mean', stats.sem])\n",
    "degree_info_ppi['order'] = [1, 2, 0]\n",
    "degree_info_ppi = degree_info_ppi.sort_values(by='order')\n",
    "degree_info_phenotype = degree_info[degree_info['graph']=='Phenotype'].groupby(['type'])['degree'].agg(['mean', stats.sem])\n",
    "degree_info_phenotype['order'] = [1, 2, 0]\n",
    "degree_info_phenotype = degree_info_phenotype.sort_values(by='order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function copied from https://stackoverflow.com/questions/11517986/indicating-the-statistically-significant-difference-in-bar-graph\n",
    "def barplot_annotate_brackets(num1, num2, data, center, height, yerr=None, dh=.05, barh=.05, fs=None, maxasterix=None):\n",
    "    \"\"\" \n",
    "    Annotate barplot with p-values.\n",
    "\n",
    "    :param num1: number of left bar to put bracket over\n",
    "    :param num2: number of right bar to put bracket over\n",
    "    :param data: string to write or number for generating asterixes\n",
    "    :param center: centers of all bars (like plt.bar() input)\n",
    "    :param height: heights of all bars (like plt.bar() input)\n",
    "    :param yerr: yerrs of all bars (like plt.bar() input)\n",
    "    :param dh: height offset over bar / bar + yerr in axes coordinates (0 to 1)\n",
    "    :param barh: bar height in axes coordinates (0 to 1)\n",
    "    :param fs: font size\n",
    "    :param maxasterix: maximum number of asterixes to write (for very small p-values)\n",
    "    \"\"\"\n",
    "\n",
    "    if type(data) is str:\n",
    "        text = data\n",
    "    else:\n",
    "        # * is p < 0.05\n",
    "        # ** is p < 0.005\n",
    "        # *** is p < 0.0005\n",
    "        # etc.\n",
    "        text = ''\n",
    "        p = .05\n",
    "\n",
    "        while data < p:\n",
    "            text += '*'\n",
    "            p /= 10.\n",
    "\n",
    "            if maxasterix and len(text) == maxasterix:\n",
    "                break\n",
    "\n",
    "        if len(text) == 0:\n",
    "            text = 'n. s.'\n",
    "\n",
    "    lx, ly = center[num1], height[num1]\n",
    "    rx, ry = center[num2], height[num2]\n",
    "\n",
    "    if yerr:\n",
    "        ly += yerr[num1]\n",
    "        ry += yerr[num2]\n",
    "\n",
    "    ax_y0, ax_y1 = plt.gca().get_ylim()\n",
    "    dh *= (ax_y1 - ax_y0)\n",
    "    barh *= (ax_y1 - ax_y0)\n",
    "\n",
    "    y = max(ly, ry) + dh\n",
    "\n",
    "    barx = [lx, lx, rx, rx]\n",
    "    bary = [y, y+barh, y+barh, y]\n",
    "    mid = ((lx+rx)/2, y+barh)\n",
    "\n",
    "    plt.plot(barx, bary, c='black')\n",
    "\n",
    "    kwargs = dict(ha='center', va='bottom')\n",
    "    if fs is not None:\n",
    "        kwargs['fontsize'] = fs\n",
    "\n",
    "    plt.text(*mid, text, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ppi = degree_info_ppi\n",
    "\n",
    "labels = ['Epilepsy-specific', \"Autism-specific\", \"Common\"]\n",
    "\n",
    "degree_ppi_means = list(df_ppi['mean'])\n",
    "degree_ppi_errors = list(df_ppi['sem'])\n",
    "\n",
    "x = np.arange(len(degree_info_ppi))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "err_kwargs = {'fmt':'none','linewidth':2,'ecolor':'k','capsize':10}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "rects1 = ax.bar(x, degree_ppi_means, width, label='PPI')\n",
    "ax.errorbar(x, degree_ppi_means, yerr=degree_ppi_errors, **err_kwargs)\n",
    "\n",
    "alpha = 0.05\n",
    "d = {0: 0.3, 1: 0.1, 2: 0.1}\n",
    "for i in range(0, len(x)):\n",
    "    for j in range(i+1, len(x)):\n",
    "        p = abs(ppi_degree.iloc[i,j])\n",
    "        if p < alpha:\n",
    "            barplot_annotate_brackets(i, j, \"p = \" + str(round_sig(p, sig=3)), x, degree_ppi_means, dh=d[i])\n",
    "\n",
    "        \n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('PPI degree')\n",
    "ax.set_xlabel('Gene group')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "plt.savefig(os.path.join(FIGURES_DIR, \"degree_significance_ppi.eps\"), dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenotype = degree_info_phenotype\n",
    "\n",
    "labels = ['Epilepsy-specific', \"Autism-specific\", \"Common\"]\n",
    "\n",
    "degree_phenotype_means = list(df_phenotype['mean'])\n",
    "degree_phenotype_errors = list(df_phenotype['sem'])\n",
    "\n",
    "x = np.arange(len(degree_info_ppi))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "err_kwargs = {'fmt':'none','linewidth':2,'ecolor':'k','capsize':10}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "rects2 = ax.bar(x, degree_phenotype_means, width, label='Phenotype')\n",
    "ax.errorbar(x, degree_phenotype_means, yerr=degree_phenotype_errors, **err_kwargs)\n",
    "\n",
    "alpha = 0.05\n",
    "d = {0: 0.3, 1: 0.1, 2: 0.1}\n",
    "for i in range(0, len(x)):\n",
    "    for j in range(i+1, len(x)):\n",
    "        p = abs(phenotype_degree.iloc[i,j])\n",
    "        if p < alpha:\n",
    "            barplot_annotate_brackets(i, j, \"p = \" + str(round_sig(p, sig=3)), x, degree_phenotype_means, dh=d[i])\n",
    "        \n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Phenotype degree')\n",
    "ax.set_xlabel('Gene group')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "plt.savefig(os.path.join(FIGURES_DIR, \"degree_significance_phenotype.eps\"), dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_info_ppi = bc_info[bc_info['graph']=='PPI'].groupby(['type'])['betweenness'].agg(['mean', stats.sem])\n",
    "bc_info_ppi['order'] = [1, 2, 0]\n",
    "bc_info_ppi = bc_info_ppi.sort_values(by='order')\n",
    "bc_info_phenotype = bc_info[bc_info['graph']=='Phenotype'].groupby(['type'])['betweenness'].agg(['mean', stats.sem])\n",
    "bc_info_phenotype['order'] = [1, 2, 0]\n",
    "bc_info_phenotype = bc_info_phenotype.sort_values(by='order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ppi = bc_info_ppi\n",
    "\n",
    "labels = ['Epilepsy-specific', \"Autism-specific\", \"Common\"]\n",
    "\n",
    "degree_ppi_means = list(df_ppi['mean'])\n",
    "degree_ppi_errors = list(df_ppi['sem'])\n",
    "\n",
    "x = np.arange(len(degree_info_ppi))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "err_kwargs = {'fmt':'none','linewidth':2,'ecolor':'k','capsize':10}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "rects1 = ax.bar(x, degree_ppi_means, width, label='PPI')\n",
    "ax.errorbar(x, degree_ppi_means, yerr=degree_ppi_errors, **err_kwargs)\n",
    "\n",
    "alpha = 0.05\n",
    "d = {0: 0.3, 1: 0.1, 2: 0.1}\n",
    "for i in range(0, len(x)):\n",
    "    for j in range(i+1, len(x)):\n",
    "        p = abs(ppi_bc.iloc[i,j])\n",
    "        if p < alpha:\n",
    "            barplot_annotate_brackets(i, j, \"p = \" + str(round_sig(p, sig=3)), x, degree_ppi_means, dh=d[i])\n",
    "\n",
    "        \n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('PPI betweenness centrality')\n",
    "ax.set_xlabel('Gene group')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "plt.savefig(os.path.join(FIGURES_DIR, \"BC_significance_ppi.eps\"), dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenotype = bc_info_phenotype\n",
    "\n",
    "labels = ['Epilepsy-specific', \"Autism-specific\", \"Common\"]\n",
    "\n",
    "degree_phenotype_means = list(df_phenotype['mean'])\n",
    "degree_phenotype_errors = list(df_phenotype['sem'])\n",
    "\n",
    "x = np.arange(len(degree_info_ppi))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "err_kwargs = {'fmt':'none','linewidth':2,'ecolor':'k','capsize':10}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "rects2 = ax.bar(x, degree_phenotype_means, width, label='Phenotype')\n",
    "ax.errorbar(x, degree_phenotype_means, yerr=degree_phenotype_errors, **err_kwargs)\n",
    "\n",
    "alpha = 0.05\n",
    "d = {0: 0.3, 1: 0.1, 2: 0.1}\n",
    "for i in range(0, len(x)):\n",
    "    for j in range(i+1, len(x)):\n",
    "        p = abs(phenotype_bc.iloc[i,j])\n",
    "        if p < alpha:\n",
    "            barplot_annotate_brackets(i, j, \"p = \" + str(round_sig(p, sig=3)), x, degree_phenotype_means, dh=d[i])\n",
    "        \n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Phenotype betweenness centrality')\n",
    "ax.set_xlabel('Gene group')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "plt.savefig(os.path.join(FIGURES_DIR, \"BC_significance_phenotype.eps\"), dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
