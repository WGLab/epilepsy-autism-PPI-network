{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables to be updated/configured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WES = False # False if running for the larger epilepsy-autism multiplex network, True if running for the WES multiplex network\n",
    "GRAPH_DIR = \"./../gexf_files\" # path to directory where the .gexf files are located\n",
    "KB_DIR = './lib/Knowledgebase'  # path to Phen2Gene KB directory\n",
    "SKEWNESS_DIR = './lib/skewness' # path to Phen2Gene directory with skewness weights\n",
    "PHENOTYPES_DIR = \"./../phenotypes\" # path to directory containing .csv files with epilepsy and autism phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "import mygene\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert gene symbol to entrez id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes in the network\n",
    "if WES:\n",
    "    input_filename = 'genes_wes.txt'\n",
    "else:\n",
    "    input_filename = 'genes.txt'\n",
    "    \n",
    "df = pd.DataFrame(pd.read_csv(input_filename).iloc[:,0])\n",
    "df.columns = ['gene_symbol']\n",
    "gene_set = set(df['gene_symbol'])\n",
    "print(\"Number of genes in the network:\", len(gene_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_to_entrezid = {\n",
    "    'MEMO1': 51072,\n",
    "    'SLCO1B7': 338821,\n",
    "    'NOTCH2NL': 388677, \n",
    "    'ST5': 6764, \n",
    "    'MT-CO1': 4512, \n",
    "    'C7orf55': 154791, \n",
    "    'MT-CYB': 4519, \n",
    "    'APOPT1': 84334, \n",
    "    'LPHN2': 23266, \n",
    "    'FAM92B': 339145, \n",
    "    'C16orf62': 57020, \n",
    "    'WHSC1': 7468,\n",
    "    'GUCY1A3': 2982, \n",
    "    'MT-ND1': 4535, \n",
    "    'COL4A3BP': 10087, \n",
    "    'C10orf2': 56652, \n",
    "    'SGK223': 157285, \n",
    "    'NGFRAP1': 27018, \n",
    "    'ATP5A1': 498,\n",
    "    'CASC4': 113201,\n",
    "    'GPR98': 84059,\n",
    "    'TTC25': 83538,\n",
    "    'MT-ND5': 4540,\n",
    "    'KIAA1456': 57604,\n",
    "    'QARS': 5859,\n",
    "    'AARS': 16,\n",
    "    'ZFYVE20': 64145,\n",
    "    'GPR56': 9289,\n",
    "    'MT-ATP8': 4509,\n",
    "    'MT-CO3': 4514,\n",
    "    'KARS': 3735,\n",
    "    'MT-ATP6': 4508,\n",
    "    'MT-ND4': 4538, \n",
    "    'LOR': 4014,\n",
    "    'SSPO': 23145,\n",
    "    'MSNP1AS': 4479,\n",
    "    'PTCHD1-AS': 100873065\n",
    "}\n",
    "gene_set_all = gene_set\n",
    "gene_set = [g for g in gene_set if g not in symbol_to_entrezid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = mygene.MyGeneInfo()\n",
    "result = mg.querymany(gene_set, scopes='symbol', species='human', returnall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no entrez id\n",
    "for m in result['missing']:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for g in result['out']:\n",
    "    if 'notfound' in g:\n",
    "        print('entrez not found:', g['query'])\n",
    "        temp.append([g['query'], -1])\n",
    "    elif 'entrezgene' not in g:\n",
    "        print('entrezgene not available:', g['query'])\n",
    "        temp.append([g['query'], -1])\n",
    "    else:\n",
    "        temp.append([g['query'], g['entrezgene']])\n",
    "\n",
    "manual_matching = [[i, symbol_to_entrezid[i]] for i in symbol_to_entrezid if i in gene_set_all]\n",
    "temp.extend(manual_matching)\n",
    "symbol_to_id_df = pd.DataFrame(temp)\n",
    "symbol_to_id_df.columns = [\"gene_symbol\", \"entrez_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_to_id_df.to_csv(input_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene gene-phenotype associations for genes in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = pd.read_csv(input_filename)\n",
    "gene_set = set(nodes_df['entrez_id'])\n",
    "gene_symbols = set(nodes_df['gene_symbol'])\n",
    "print(\"Number of entrez IDs:\", len(gene_set)) # 2 genes are -1 entrez id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(os.listdir(KB_DIR))\n",
    "print(\"Retrieving gene-phenotype associations from Phen2Gene knowledge base\")\n",
    "with open('temp.txt', 'w') as output:\n",
    "    for idx, file in enumerate(os.listdir(KB_DIR)):\n",
    "\n",
    "        if idx % 500 == 0:\n",
    "            print(f\"{idx}/{n}\")\n",
    "\n",
    "        hpo = file.replace('.candidate_gene_list', '')\n",
    "        \n",
    "        # loop through each line in candidate gene list file\n",
    "        with open(os.path.join(KB_DIR, file)) as f:\n",
    "            for i, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                \n",
    "                if i == 0: # skip first line of file\n",
    "                    if idx == 0:\n",
    "                        splits = line.split(\"\\t\") + [\"HPO\"]\n",
    "                        output.write(\"\\t\".join(splits) + \"\\n\")\n",
    "                    continue\n",
    "\n",
    "                splits = line.split(\"\\t\") + [hpo]\n",
    "                if int(splits[2].strip()) in gene_set:\n",
    "                    output.write(\"\\t\".join(splits) + \"\\n\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply gene-phenotype association by skewness\n",
    "df = pd.read_csv('temp.txt', sep=\"\\t\")\n",
    "os.remove(\"temp.txt\")\n",
    "\n",
    "skewness_values = []\n",
    "for file in os.listdir(SKEWNESS_DIR):\n",
    "    with open(os.path.join(SKEWNESS_DIR, file), 'r') as f:\n",
    "        hpo = file\n",
    "        skewness = float(f.read().strip())\n",
    "        skewness_values.append([hpo, skewness])\n",
    "skewness_df = pd.DataFrame(skewness_values)\n",
    "skewness_df.columns = [\"HPO\", \"skewness\"]\n",
    "\n",
    "hpo_associations_df = df.merge(skewness_df, on=\"HPO\", how=\"left\")\n",
    "hpo_associations_df['final_score'] = hpo_associations_df['Score'] * hpo_associations_df['skewness']\n",
    "hpo_associations_df = hpo_associations_df.merge(nodes_df, left_on=\"ID\", right_on=\"entrez_id\")\n",
    "\n",
    "if WES:\n",
    "    hpo_associations_df.to_csv(\"hpo_association_scores_wes.csv\", index=False)\n",
    "else:\n",
    "    hpo_associations_df.to_csv(\"hpo_association_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct phenotype network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WES:\n",
    "    rank = 500\n",
    "else:\n",
    "    rank = 1000\n",
    "alpha = 0.01\n",
    "\n",
    "hpo_associations_df = hpo_associations_df[hpo_associations_df[\"Rank\"] <= rank] # only use rank top genes per HPO ID\n",
    "hpo_associations_df = hpo_associations_df.pivot(index='gene_symbol', columns='HPO', values='final_score')\n",
    "hpo_associations_df = hpo_associations_df.fillna(0)\n",
    "doc_term_matrix = hpo_associations_df.values\n",
    "\n",
    "cs_comp = cosine_similarity(doc_term_matrix, doc_term_matrix) # actual cosine similarity between phenotype vectors of genes\n",
    "num_trials = 1000\n",
    "result = np.zeros((len(cs_comp), len(cs_comp)))\n",
    "print('Shuffling phenotype vectors')\n",
    "for n in range(0, num_trials):\n",
    "    if n % 50 == 0:\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(\"Trial\", n, \"Current Time =\", current_time)\n",
    "    np.random.shuffle(doc_term_matrix)\n",
    "    cs = cosine_similarity(doc_term_matrix, doc_term_matrix) # cosine similarity between shuffled phenotype vectors of genes\n",
    "    result = np.add(result, np.greater(cs, cs_comp))\n",
    "\n",
    "\n",
    "genes = list(hpo_associations_df.index)\n",
    "edges = []\n",
    "alpha = alpha\n",
    "n = len(cs_comp)\n",
    "print('Adding edges to phenotype network')\n",
    "for i in range(0, n):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Node {i}/{n}\")\n",
    "    for j in range(i+1, n):\n",
    "        thresh = int(num_trials * alpha) \n",
    "        if result[i, j] < thresh: # lower number of random shuffles with greater cosine similarity, compared to threshold\n",
    "            edges.append((genes[i], genes[j]))\n",
    "\n",
    "G_phenotype = nx.Graph()\n",
    "G_phenotype.add_nodes_from(gene_symbols)\n",
    "G_phenotype.add_edges_from(edges)\n",
    "print(nx.info(G_phenotype))\n",
    "\n",
    "if WES:\n",
    "    nx.write_gexf(G_phenotype, os.path.join(GRAPH_DIR, \"gene-phenotype-wes-1-500.gexf\"))\n",
    "else:\n",
    "    nx.write_gexf(G_phenotype, os.path.join(GRAPH_DIR, \"gene-phenotype-1-1000.gexf\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate gene-phenotype associations for all genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epilepsy_phenotypes_df = pd.read_csv(os.path.join(PHENOTYPES_DIR, \"epilepsy_phenotypes.csv\")) # epilepsy phenotypes (HPO subtree with root Autistic behavior HP:0000729)\n",
    "autism_phenotypes_df = pd.read_csv(os.path.join(PHENOTYPES_DIR, \"autism_phenotypes.csv\")) # autism phenotypes (HPO subtree with root Seizure HP:0001250)\n",
    "epilepsy_phenotypes = set(epilepsy_phenotypes_df['HPO'])\n",
    "autism_phenotypes = set(autism_phenotypes_df['HPO'])\n",
    "ea_phenotypes = epilepsy_phenotypes.union(autism_phenotypes)\n",
    "ea_phenotypes = [i.replace(\":\", \"_\") for i in ea_phenotypes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(os.listdir(KB_DIR))\n",
    "print(\"Retrieving gene-phenotype associations from Phen2Gene knowledge base\")\n",
    "with open('temp.txt', 'w') as output:\n",
    "    output.write(\"Rank\tGene\tID\tScore\tStatus\tHPO\\n\")\n",
    "    for idx, file in enumerate(os.listdir(KB_DIR)):\n",
    "\n",
    "        if idx % 500 == 0:\n",
    "            print(f\"{idx}/{n}\")\n",
    "\n",
    "        hpo = file.replace('.candidate_gene_list', '')\n",
    "        if hpo not in ea_phenotypes: # only need gene-phenotype associations for epilepsy/autism phenotypes\n",
    "            continue\n",
    "        \n",
    "        # loop through each line in candidate gene list file\n",
    "        with open(os.path.join(KB_DIR, file)) as f:\n",
    "            for i, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                \n",
    "                if i == 0: # skip first line of file\n",
    "                    continue\n",
    "\n",
    "                splits = line.split(\"\\t\") + [hpo]\n",
    "                output.write(\"\\t\".join(splits) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('temp.txt', sep=\"\\t\")\n",
    "os.remove(\"temp.txt\")\n",
    "\n",
    "skewness_values = []\n",
    "for file in os.listdir(SKEWNESS_DIR):\n",
    "    with open(os.path.join(SKEWNESS_DIR, file), 'r') as f:\n",
    "        hpo = file\n",
    "        if hpo not in ea_phenotypes:\n",
    "            continue\n",
    "        skewness = float(f.read().strip())\n",
    "        skewness_values.append([hpo, skewness])\n",
    "skewness_df = pd.DataFrame(skewness_values)\n",
    "skewness_df.columns = [\"HPO\", \"skewness\"]\n",
    "\n",
    "hpo_associations_df = df.merge(skewness_df, on=\"HPO\", how=\"left\")\n",
    "hpo_associations_df['final_score'] = hpo_associations_df['Score'] * hpo_associations_df['skewness']\n",
    "hpo_associations_df.to_csv(\"hpo_association_scores_all.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
