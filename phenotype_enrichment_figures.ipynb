{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables to be updated/configured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WES = False # False if running for the larger epilepsy-autism multiplex network, True if running for the WES multiplex network\n",
    "\n",
    "if WES:\n",
    "    FIGURES_DIR = \"figures_wes\" # path to directory where figures will the saved (creates the directory if it doesn't exist)\n",
    "    COMS_DIR = \"communities_wes\" # path to directory containing information on the communities in the network\n",
    "else:\n",
    "    FIGURES_DIR = \"figures\" # path to directory where figures will the saved (creates the directory if it doesn't exist)\n",
    "    COMS_DIR = \"communities\" # path to directory containing information on the communities in the network\n",
    "    \n",
    "GRAPH_DIR = \"gexf_files\" # path to directory where the .gexf files are located\n",
    "PHENOTYPES_DIR = \"phenotypes\" # path to directory containing .csv files with epilepsy and autism phenotypes\n",
    "TABLES_DIR = \"tables\" # path to directory containing .csv files representing tables (creates the directory if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# network packages\n",
    "import networkx as nx\n",
    "from networkx.readwrite.gexf import read_gexf\n",
    "\n",
    "# visualization packages\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# other packages\n",
    "from math import floor, log10\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "# packages for calculating linkage\n",
    "import scipy\n",
    "from itertools import combinations\n",
    "from scipy.cluster.hierarchy import linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size': 14}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TABLES_DIR):\n",
    "    os.makedirs(TABLES_DIR)\n",
    "if not os.path.exists(FIGURES_DIR):\n",
    "    os.makedirs(FIGURES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WES:\n",
    "    gene_phenotype_filename = 'gene-phenotype-wes-1-500-update.gexf'\n",
    "    gene_ppi_filename = \"gene-ppi-wes-700-update.gexf\"\n",
    "    gene_union_filename = 'gene-union-wes.gexf'\n",
    "else:\n",
    "    gene_phenotype_filename = 'gene-phenotype-1-1000-update.gexf'\n",
    "    gene_ppi_filename = 'gene-ppi-700-update.gexf'\n",
    "    gene_union_filename = 'gene-union.gexf'\n",
    "    \n",
    "gene_phenotype = read_gexf(os.path.join(GRAPH_DIR, gene_phenotype_filename))\n",
    "gene_ppi = read_gexf(os.path.join(GRAPH_DIR, gene_ppi_filename))\n",
    "gene_union = read_gexf(os.path.join(GRAPH_DIR, gene_union_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper for communities\n",
    "class Coms:\n",
    "    def __init__(self, communities):\n",
    "        self.communities = communities\n",
    "        self.overlap = None\n",
    "        \n",
    "# get Coms class with genes from annotated networkx graph\n",
    "def get_coms_from_graph(G):    \n",
    "    max_module = max([G.nodes[node]['module'] for node in G.nodes])\n",
    "    partition = []\n",
    "    for i in range(max_module):\n",
    "        partition.append([])\n",
    "    for node in G.nodes:\n",
    "        mod = G.nodes[node]['module']\n",
    "        partition[mod-1] = partition[mod-1] + [node]\n",
    "    coms = Coms(partition)\n",
    "    return coms\n",
    "\n",
    "# takes partition with IDs and converts to Coms class with genes\n",
    "def partition_to_genes(partition):\n",
    "    partition_genes = []\n",
    "    for com in partition:\n",
    "        com_genes = []\n",
    "        for g in com:\n",
    "            com_genes.append(id_to_gene[g])\n",
    "        partition_genes.append(com_genes) \n",
    "    coms = Coms(list(partition_genes))\n",
    "    return coms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coms_ppi = get_coms_from_graph(gene_ppi)\n",
    "coms_phenotype = get_coms_from_graph(gene_phenotype)\n",
    "coms_multiplex = get_coms_from_graph(gene_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epilepsy_phenotypes_df = pd.read_csv(os.path.join(PHENOTYPES_DIR, \"epilepsy_phenotypes.csv\"))\n",
    "autism_phenotypes_df = pd.read_csv(os.path.join(PHENOTYPES_DIR, \"autism_phenotypes.csv\"))\n",
    "epilepsy_phenotypes = set(epilepsy_phenotypes_df['HPO'])\n",
    "autism_phenotypes = set(autism_phenotypes_df['HPO'])\n",
    "\n",
    "print(f\"{len(epilepsy_phenotypes)} HPO terms under seizure (HP:0001250)\")\n",
    "print(f\"{len(autism_phenotypes)} HPO terms under autistic behavior (HP:0000729)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot phenotype enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_p_val_label(x, vmax):\n",
    "    if vmax and x >= vmax:\n",
    "        return \"****\"\n",
    "    elif x > -np.log10(0.01):\n",
    "        return \"***\"\n",
    "    elif x > -np.log10(0.05):\n",
    "        return \"**\"\n",
    "    elif x > -np.log10(0.1):\n",
    "        return \"*\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def plot_enrichment_w_linkage(enrichment_df, mod_sizes, filename, vmax=None, row_linkage=None, figsize=(20, 10)):\n",
    "\n",
    "    sns.set(font_scale=0.8)\n",
    "\n",
    "    num_mods = len(enrichment_df.columns)\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    xticklabels = []\n",
    "    for i in range(1, num_mods+1):\n",
    "        xticklabels.append(f'{str(i)}\\n({mod_sizes[i-1]})')\n",
    "    \n",
    "    labels_df = enrichment_df.applymap(lambda x: neg_log_p_val_label(x, vmax))\n",
    "\n",
    "    cmap = \"Blues\"\n",
    "    g = sns.clustermap(enrichment_df, row_linkage=row_linkage, col_cluster=False, col_linkage=None, annot=labels_df, fmt=\"\", yticklabels = list(enrichment_df.index), xticklabels = xticklabels, cbar_kws={'label': '-log10(FDR)'}, cmap=cmap, vmin=0, vmax=vmax)\n",
    "    \n",
    "    ax = g.ax_heatmap\n",
    "    \n",
    "    colorbar = ax.collections[0].colorbar\n",
    "    if vmax:\n",
    "        colorbar.set_ticks(list(np.arange(0, vmax, max(int(vmax/3)-int(vmax/5), 1))) + [vmax])\n",
    "        colorbar.set_ticklabels(list(np.arange(0, vmax, max(int(vmax/4)-int(vmax/7), 1))) + [str(round(vmax, 3)) + \"+\"])\n",
    "    \n",
    "    ax.set_xlabel('Module\\n(size)')\n",
    "    ax.set_ylabel('HPO')\n",
    "\n",
    "    g.savefig(filename, dpi=600)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_enrichment(enrichment_df, mod_sizes, filename, vmax=None):\n",
    "\n",
    "    num_mods = len(enrichment_df.columns)\n",
    "    plt.figure(figsize=(16,12))\n",
    "\n",
    "    xticklabels = []\n",
    "    for i in range(1, num_mods+1):\n",
    "        xticklabels.append(f'{str(i)}\\n({mod_sizes[i-1]})')\n",
    "    \n",
    "    labels_df = enrichment_df.applymap(lambda x: neg_log_p_val_label(x, vmax))\n",
    "\n",
    "    cmap = \"Blues\"\n",
    "    ax = sns.heatmap(enrichment_df, annot=labels_df, fmt=\"\", xticklabels = xticklabels, cbar_kws={'label': '-log10(FDR)'}, cmap=cmap, vmin=0, vmax=vmax)\n",
    "    colorbar = ax.collections[0].colorbar\n",
    "    \n",
    "    if vmax:\n",
    "        colorbar.set_ticks(list(np.arange(0, vmax, 1)) + [vmax])\n",
    "        colorbar.set_ticklabels(list(np.arange(0, vmax, 1)) + [str(round(vmax, 3)) + \"+\"])\n",
    "\n",
    "    plt.xlabel('Module\\n(size)')\n",
    "    plt.ylabel('Gene group')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(filename, dpi=600)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enrichments_matrix_phenotype(df, labels=sorted(list(epilepsy_phenotypes)) + sorted(list(autism_phenotypes))):\n",
    "    \n",
    "    enrichments = df    \n",
    "    fdr_list = []\n",
    "    for mod_num in range(1, max(df['module'])+1):\n",
    "        rejected, fdr = fdrcorrection(list(enrichments[enrichments['module']==mod_num]['p_val'])) # FDR correction\n",
    "        fdr_list = fdr_list + list(fdr)\n",
    "\n",
    "    enrichments['p_adjusted'] = fdr_list\n",
    "    enrichments['neg_log_pval'] = -np.log10(enrichments['p_adjusted'])\n",
    "    \n",
    "    temp = []\n",
    "    for i, label in enumerate(labels):\n",
    "        pvals = list(enrichments[enrichments['HPO']==label].sort_values(by='module')['neg_log_pval'])\n",
    "        temp.append(pvals)\n",
    "\n",
    "    enrichment_df = pd.DataFrame(temp)\n",
    "    enrichment_df.index = labels\n",
    "    return enrichment_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dendrogram(df, root, hpos):\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.merge(df, left_on='HPO', right_on='parent', how='left').drop('parent_y', axis=1)\n",
    "    df.columns = ['HPO', 'parent', 'children']\n",
    "    leaves = sorted(list(set(df[pd.isna(df['children'])]['HPO'])))\n",
    "    df = df.fillna(0)\n",
    "    df = df.groupby(['HPO', 'parent'])['children'].apply(lambda x: sorted(list(x))).reset_index()\n",
    "\n",
    "    hpo = set(df['HPO'])\n",
    "    non_leaves = (hpo.difference(set(leaves)))\n",
    "    if root in non_leaves:\n",
    "        non_leaves.remove(root)\n",
    "\n",
    "    hpo_to_id = {}\n",
    "    for i, h in enumerate(leaves):\n",
    "        hpo_to_id[h] = i\n",
    "\n",
    "    for i, h in enumerate(non_leaves, len(leaves)):\n",
    "        hpo_to_id[h] = i\n",
    "\n",
    "    hpo_to_id[root] = len(hpo) - 1\n",
    "\n",
    "    hpo_to_children = {}\n",
    "    for i, row in df.iterrows():\n",
    "        hpo_to_children[row['HPO']] = row['children']\n",
    "\n",
    "    # create tree\n",
    "    G = nx.Graph()\n",
    "    q = [root]\n",
    "    while q:\n",
    "        node = q.pop()\n",
    "        children = hpo_to_children[node]\n",
    "        children = [c for c in children if c]\n",
    "        for child in children:\n",
    "            G.add_edge(hpo_to_id[child], hpo_to_id[node])\n",
    "        q = q + children\n",
    "\n",
    "    # get distances between HPO IDs in tree to generate dendrogram\n",
    "    n = len(G.nodes)\n",
    "    dmat = np.zeros((n, n))\n",
    "    for l1, l2 in combinations(list(G.nodes), 2): #hpo_leaves\n",
    "        res = nx.shortest_path(G, source=l1, target=l2)\n",
    "        dmat[l1, l2] = len(res) - 1\n",
    "        dmat[l2, l1] = len(res) - 1\n",
    "        \n",
    "    if 'HP:0001250' in hpo_to_id and 'HP:0000729' in hpo_to_id:\n",
    "        dmat[hpo_to_id['HP:0001250'], hpo_to_id['HP:0000729']] = 1000\n",
    "        dmat[hpo_to_id['HP:0000729'], hpo_to_id['HP:0001250']] = 1000\n",
    "        \n",
    "    n = len(hpos)\n",
    "    dmat_updated = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            dmat_updated[i, j] = dmat[hpo_to_id[hpos[i]], hpo_to_id[hpos[j]]]\n",
    "            dmat_updated[j, i] = dmat[hpo_to_id[hpos[j]], hpo_to_id[hpos[i]]]\n",
    "    \n",
    "    schlink = linkage(scipy.spatial.distance.squareform(dmat_updated), method='average', metric='euclidean')\n",
    "    return schlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_hpo_name(df, labels_df):\n",
    "    df = df.merge(labels_df, left_index=True, right_on='HPO', how='left').fillna('')\n",
    "    df.index = df['HPO'] + \" \" + df['HPO_name']\n",
    "    df = df.drop(['HPO', 'HPO_name'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_sig(x, sig=3):\n",
    "    return round(x, sig-int(floor(log10(abs(x))))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype enrichment (experimental) in multiplex network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_ppi_sizes = [len(com) for com in coms_ppi.communities]\n",
    "com_phenotype_sizes = [len(com) for com in coms_phenotype.communities]\n",
    "com_multiplex_sizes = [len(com) for com in coms_multiplex.communities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enrichment using experimental p-value\n",
    "if WES:\n",
    "    TOP_MODULES = 13    \n",
    "else:\n",
    "    TOP_MODULES = 14\n",
    "    \n",
    "coms_multiplex_enrichment_df = pd.read_csv(os.path.join(COMS_DIR, 'coms_multiplex_phenotype_enrichment.csv'))\n",
    "coms_multiplex_enrichment_df_all = pd.read_csv(os.path.join(COMS_DIR, 'coms_multiplex_phenotype_enrichment_all.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_sizes = com_multiplex_sizes\n",
    "enrichment_df = get_enrichments_matrix_phenotype(coms_multiplex_enrichment_df).iloc[:,:TOP_MODULES].dropna()\n",
    "enrichment_df_all = get_enrichments_matrix_phenotype(coms_multiplex_enrichment_df_all).iloc[:,:TOP_MODULES].dropna()\n",
    "\n",
    "# cap the enrichment value at the max value if it is np.inf\n",
    "vmax = np.amax(enrichment_df.replace(np.inf, -1).values)\n",
    "enrichment_df = enrichment_df.replace(np.inf, vmax)\n",
    "vmax_all = np.amax(enrichment_df_all.replace(np.inf, -1).values)\n",
    "enrichment_df_all = enrichment_df_all.replace(np.inf, vmax_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the row linkage dendrogram\n",
    "df = epilepsy_phenotypes_df.append(autism_phenotypes_df).drop_duplicates()\n",
    "df = df.append({'HPO': 'root', 'parent': 'head'}, ignore_index=True)\n",
    "row_linkage = get_dendrogram(df[['HPO', 'parent']], root='root', hpos=list(enrichment_df.index))\n",
    "row_linkage_all = get_dendrogram(df[['HPO', 'parent']], root='root', hpos=list(enrichment_df_all.index))\n",
    "\n",
    "# update heatmap labels\n",
    "hpo_labels_df = df[['HPO', 'HPO_name']].drop_duplicates()\n",
    "enrichment_df = format_hpo_name(enrichment_df, hpo_labels_df)\n",
    "enrichment_df_all = format_hpo_name(enrichment_df_all, hpo_labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_enrichment_w_linkage(enrichment_df, mod_sizes, os.path.join(FIGURES_DIR, 'phenotype_enrichment_multiplex.png'), vmax=vmax, row_linkage=row_linkage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_enrichment_w_linkage(enrichment_df_all, mod_sizes, os.path.join(FIGURES_DIR, 'phenotype_enrichment_multiplex_all.png'), vmax=vmax_all, row_linkage=row_linkage_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype enrichment (JAX gene-phenotype associations) in multiplex network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hpo jax enrichment epilepsy autism HPO\n",
    "if WES:\n",
    "    TOP_MODULES = 13\n",
    "\n",
    "else:\n",
    "    TOP_MODULES = 14\n",
    "    \n",
    "# from HPO jax\n",
    "coms_multiplex_enrichment_df = pd.read_csv(os.path.join(COMS_DIR, 'coms_multiplex_enrichment.csv')).fillna(1)\n",
    "coms_multiplex_enrichment_df = coms_multiplex_enrichment_df[coms_multiplex_enrichment_df['label'].str.contains(\"HP:\")]\n",
    "coms_multiplex_enrichment_df = coms_multiplex_enrichment_df.rename(columns={'label': 'HPO', 'pval': 'p_val'})\n",
    "\n",
    "coms_multiplex_enrichment_df_all = pd.read_csv(os.path.join(COMS_DIR, 'coms_multiplex_enrichment_all_genes.csv')).fillna(1)\n",
    "coms_multiplex_enrichment_df_all = coms_multiplex_enrichment_df_all[coms_multiplex_enrichment_df_all['label'].str.contains(\"HP:\")]\n",
    "coms_multiplex_enrichment_df_all = coms_multiplex_enrichment_df_all.rename(columns={'label': 'HPO', 'pval': 'p_val'})\n",
    "    \n",
    "enrichment_df = get_enrichments_matrix_phenotype(coms_multiplex_enrichment_df).iloc[:,:TOP_MODULES].dropna()\n",
    "enrichment_df_all = get_enrichments_matrix_phenotype(coms_multiplex_enrichment_df_all).iloc[:,:TOP_MODULES].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with all zero enrichment\n",
    "enrichment = enrichment_df[enrichment_df.index.isin(epilepsy_phenotypes.union(autism_phenotypes))]\n",
    "enrichment = enrichment.replace(0, np.nan).dropna(axis=0, how=\"all\").replace(np.nan, 0)\n",
    "enrichment_all = enrichment_df_all[enrichment_df_all.index.isin(epilepsy_phenotypes.union(autism_phenotypes))]\n",
    "enrichment_all = enrichment_all.replace(0, np.nan).dropna(axis=0, how=\"all\").replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the row linkage dendrogram\n",
    "df = epilepsy_phenotypes_df.append(autism_phenotypes_df).drop_duplicates()\n",
    "df = df.append({'HPO': 'root', 'parent': 'head'}, ignore_index=True)\n",
    "row_linkage = get_dendrogram(df[['HPO', 'parent']], root='root', hpos=list(enrichment.index))\n",
    "row_linkage_all = get_dendrogram(df[['HPO', 'parent']], root='root', hpos=list(enrichment_all.index))\n",
    "\n",
    "# update heatmap labels\n",
    "hpo_labels_df = df[['HPO', 'HPO_name']].drop_duplicates()\n",
    "enrichment = format_hpo_name(enrichment, hpo_labels_df)\n",
    "enrichment_all = format_hpo_name(enrichment_all, hpo_labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_enrichment_w_linkage(enrichment, mod_sizes, os.path.join(FIGURES_DIR, 'phenotype_enrichment_multiplex_jax.png'), row_linkage=row_linkage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_enrichment_w_linkage(enrichment_all, mod_sizes, os.path.join(FIGURES_DIR, 'phenotype_enrichment_multiplex_jax_all.png'), row_linkage=row_linkage_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top enriched HPO (all HPO) in each module using JAX gene-phenotype associations\n",
    "Part of Supplemental Tables 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell takes several minutes to run\n",
    "if WES:\n",
    "    TOP_MODULES = 13\n",
    "else:\n",
    "    TOP_MODULES = 14\n",
    "\n",
    "coms_multiplex_enrichment_df_all = pd.read_csv(os.path.join(COMS_DIR, 'coms_multiplex_enrichment_all_hpo_all_genes.csv')).dropna()\n",
    "coms_multiplex_enrichment_df_all = coms_multiplex_enrichment_df_all[coms_multiplex_enrichment_df_all['label'].str.contains(\"HP:\")]\n",
    "coms_multiplex_enrichment_df_all = coms_multiplex_enrichment_df_all.rename(columns={'label': 'HPO', 'pval': 'p_val'})\n",
    "\n",
    "labels_all = sorted(list(set(coms_multiplex_enrichment_df_all['HPO'])))\n",
    "enrichment_df_all = get_enrichments_matrix_phenotype(coms_multiplex_enrichment_df_all, labels=labels_all).iloc[:,:TOP_MODULES].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hpo_in_modules = []\n",
    "for mod_num in range(1, TOP_MODULES + 1):\n",
    "    top_hpo = coms_multiplex_enrichment_df_all[coms_multiplex_enrichment_df_all['module']==mod_num].sort_values(by='p_adjusted').head(10)\n",
    "    hpos = list(top_hpo['HPO'])\n",
    "    hpo_name = list(top_hpo['phenotype_name'])\n",
    "    pvals = list(top_hpo['p_adjusted'])\n",
    "    \n",
    "    hpo_list = []\n",
    "    for i in range(len(hpos)):\n",
    "        hpo_list.append(f\"{hpo_name[i]} ({hpos[i]}) (FDR={round_sig(pvals[i], 3)})\")\n",
    "        \n",
    "    top_hpo_in_modules.append(\"; \".join(hpo_list))\n",
    "top_modules_df_all = pd.DataFrame(top_hpo_in_modules, columns=[\"top_hpo\"])\n",
    "top_modules_df_all['module'] = np.arange(1, TOP_MODULES + 1)\n",
    "if WES:\n",
    "    top_modules_df_all.to_csv(os.path.join(TABLES_DIR, 'top_hpo_per_module_all_genes_wes.csv'), index=False)    \n",
    "else:\n",
    "    top_modules_df_all.to_csv(os.path.join(TABLES_DIR, 'top_hpo_per_module_all_genes.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype enrichment (experimental) in PPI network layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WES:\n",
    "    TOP_MODULES = 13    \n",
    "else:\n",
    "    TOP_MODULES = 17\n",
    "\n",
    "coms_enrichment_df = pd.read_csv(os.path.join(COMS_DIR, 'coms_ppi_phenotype_enrichment.csv'))\n",
    "coms_enrichment_df_all = pd.read_csv(os.path.join(COMS_DIR, 'coms_ppi_phenotype_enrichment_all.csv'))\n",
    "  \n",
    "enrichment_df = get_enrichments_matrix_phenotype(coms_enrichment_df).iloc[:,:TOP_MODULES].dropna()\n",
    "enrichment_df_all = get_enrichments_matrix_phenotype(coms_enrichment_df_all).iloc[:,:TOP_MODULES].dropna()\n",
    "mod_sizes = com_phenotype_sizes\n",
    "\n",
    "vmax = np.amax(enrichment_df.replace(np.inf, -1).values)\n",
    "enrichment_df = enrichment_df.replace(np.inf, vmax)\n",
    "vmax = np.amax(enrichment_df_all.replace(np.inf, -1).values)\n",
    "enrichment_df_all = enrichment_df_all.replace(np.inf, vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_enrichment(enrichment_df, mod_sizes, os.path.join(FIGURES_DIR, 'phenotype_enrichment_ppi.png'), vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_enrichment(enrichment_df_all, mod_sizes, os.path.join(FIGURES_DIR, 'phenotype_enrichment_ppi_all.png'), vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype enrichment (experimental) in phentype network layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WES:\n",
    "    TOP_MODULES = 13    \n",
    "else:\n",
    "    TOP_MODULES = 18\n",
    "    \n",
    "coms_enrichment_df = pd.read_csv(os.path.join(COMS_DIR, 'coms_phenotype_phenotype_enrichment.csv'))\n",
    "coms_enrichment_df_all = pd.read_csv(os.path.join(COMS_DIR, 'coms_phenotype_phenotype_enrichment_all.csv'))\n",
    "\n",
    "enrichment_df = get_enrichments_matrix_phenotype(coms_enrichment_df).iloc[:,:TOP_MODULES].dropna()\n",
    "enrichment_df_all = get_enrichments_matrix_phenotype(coms_enrichment_df_all).iloc[:,:TOP_MODULES].dropna()\n",
    "mod_sizes = com_ppi_sizes\n",
    "\n",
    "vmax = np.amax(enrichment_df.replace(np.inf, -1).values)\n",
    "enrichment_df = enrichment_df.replace(np.inf, vmax)\n",
    "vmax = np.amax(enrichment_df_all.replace(np.inf, -1).values)\n",
    "enrichment_df_all = enrichment_df_all.replace(np.inf, vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_enrichment(enrichment_df, mod_sizes, os.path.join(FIGURES_DIR, 'phenotype_enrichment_phenotype.png'), vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_enrichment(enrichment_df_all, mod_sizes, os.path.join(FIGURES_DIR, 'phenotype_enrichment_phenotype_all.png'), vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
